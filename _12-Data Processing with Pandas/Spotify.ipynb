{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69306121-3f0f-4dd5-9043-05d3b7144507",
   "metadata": {},
   "source": [
    "# Data Processing with Pandas - Spotify Top 50 Tracks of 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eed1050-667d-412f-8eb1-0a25b779a5ae",
   "metadata": {},
   "source": [
    "Ever wondered what makes a song a global hit? This analysis dives into Spotify's Top 50 tracks of 2020 to uncover the hidden musical DNA that defines popular music, from energy levels to danceability, and how these attributes shape our listening experiences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f9b923-9755-4e0d-b784-71578165c61a",
   "metadata": {},
   "source": [
    "### Key Questions to Answer:\n",
    "\n",
    "1. What are the dominant genres in 2020's top charts?\n",
    "2. Are there specific audio features that consistently appear in popular tracks?\n",
    "3. Can we identify distinct 'types' of hit songs based on their characteristics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823d562f-63aa-49ed-9094-3a6c2b5c5b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import neccessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b681cd-7f9d-43d5-a17a-2fb1baa734da",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext blackcellmagic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537aea3a-2da2-4f38-96b2-5780a2dde2c7",
   "metadata": {},
   "source": [
    "## 1. Load & Display Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca3f650-765d-4c69-9205-c943fcea7acf",
   "metadata": {},
   "source": [
    "First, we load the data and inspect its structure to ensure it's ready for analysis. We'll check the first few rows and column data types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0101dd-7830-4da7-8722-f9a3be8ed3c0",
   "metadata": {},
   "source": [
    "The CSV file has its own index column, so we instruct pandas to use the first column (index 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f741f763-a692-4abd-802b-169c0d21b407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV file and set the first column as the DataFrame index\n",
    "df = pd.read_csv(\"spotify/spotifytoptracks.csv\", index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7054bea-b469-4e67-a05b-d782036791df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic info about the generated data\n",
    "print(f\"\\nDataFrame Info:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614ef9c5-ccc1-4024-ab9b-f652f2891fa3",
   "metadata": {},
   "source": [
    "#### Initial Data Overview:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9233bdb2-de24-4181-8f03-e99c840b27c6",
   "metadata": {},
   "source": [
    "- Dataset contains 50 rows and 16 columns\n",
    "- There are no missing values\n",
    "- Provides an overview of popular music attributes: energy, danceability, key, loudness, acousticness, speechiness, instrumentalness, liveness, valence, tempo, duration_ms.\n",
    "- **Note:** duration_ms is in miliseconds. We will convert it to minutes and seconds later\n",
    "- Provides genres: R&B/Soul, Alternative/Indie, Hip-Hop/Rap, Dance/Electronic, etc.\n",
    "- The dataset is relatively small, consuming only 6.6+ KB of memory, making it efficient to work with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860c06e6-1584-4ac1-904d-89644c5c68ab",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19543915-14b5-49cb-855a-2fa6d87fcbf0",
   "metadata": {},
   "source": [
    "Standardize text formatting, remove redundant columns, and address missing and duplicate values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4262e1-479a-4dff-809f-adae0e2af344",
   "metadata": {},
   "source": [
    "### 2.1. String Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebd38f3-e51c-4fec-bc8c-c649ce9c90e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capitalize the first letter of each word in selected columns\n",
    "text_cols = [\"artist\", \"album\", \"track_name\"]\n",
    "for col in text_cols:\n",
    "    df[col] = df[col].str.title()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffafbf8e-c666-4046-b70d-b242b49d8b45",
   "metadata": {},
   "source": [
    "### 2.2. Removing Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de56529-cecb-45af-af4c-5f8225c0b4d6",
   "metadata": {},
   "source": [
    "Removing track_id that is a unique identifier not needed for aggregate trend analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54264356-d3d3-4c4c-989e-062c22bc706b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminating \"track_id\" since it's irrelevant for analysis\n",
    "df.drop(\"track_id\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915482e3-d2c0-4d4e-8cde-9f17f2f2ae17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717065ad-ae25-4307-8b34-2d9f37d72602",
   "metadata": {},
   "source": [
    "### 2.3. Handling missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5c83ba-ef8b-4e3c-b950-6ba2860cdc12",
   "metadata": {},
   "source": [
    "As previously noted, this dataset contains no missing values. This section is included for future re-use, when dataset with missing values require processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c025d71a-0aca-4b97-91d2-70bac12d253b",
   "metadata": {},
   "source": [
    "Display existing missing value rows before deletion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9522ff-0529-43dd-951d-04ff414462f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_missing_rows(df):\n",
    "    \"\"\"\n",
    "    Check and display rows with missing values in the DataFrame\n",
    "    \"\"\"\n",
    "    missing_rows = df[df.isnull().any(axis=1)]\n",
    "    if not missing_rows.empty:\n",
    "        print(\"Rows with missing values found:\")\n",
    "        display(missing_rows)\n",
    "    else:\n",
    "        print(\"No missing values found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03eb53fb-4ddb-471c-91d7-c2bfdb95d000",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_missing_rows(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b896c2-ef44-4b09-950d-283c58385e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any rows from the DataFrame that contain missing values\n",
    "# df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21586064-47b5-4d99-a02d-124c924a2a78",
   "metadata": {},
   "source": [
    "### 2.4. Display and remove duplicate samples and features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68f2140-a0a5-4e9c-8a54-5a2d277b967b",
   "metadata": {},
   "source": [
    "Display existing duplicate values before deletion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638fcf43-5a7e-45ae-8064-c6613a70c57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_duplicate_df(df):\n",
    "    \"\"\"\n",
    "    Detects and removes duplicate rows and columns from the DataFrame.\n",
    "    \"\"\"\n",
    "    duplicate_rows = df[df.duplicated(keep=False)]\n",
    "    duplicate_cols = df.columns[df.T.duplicated()]\n",
    "\n",
    "    if not duplicate_rows.empty:\n",
    "        print(\"Duplicate samples found:\")\n",
    "        display(duplicate_rows)\n",
    "    else:\n",
    "        print(\"No duplicate samples found.\")\n",
    "\n",
    "    if len(duplicate_cols) > 0:\n",
    "        print(\"Duplicate features found:\", list(duplicate_cols))\n",
    "    else:\n",
    "        print(\"No duplicate features found.\")\n",
    "\n",
    "    df = df.drop_duplicates().loc[:, ~df.T.duplicated()]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e2de77-6c57-477e-bdc6-8ffe707d605d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = handle_duplicate_df(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf6a67d-a163-4ad9-90dc-ca09142d69ab",
   "metadata": {},
   "source": [
    "### 2.5. Treating outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ad9ef5-7ea2-4fa8-b24f-a2b1cce5b974",
   "metadata": {},
   "source": [
    "#### 2.5.1. Perform normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecea38fc-b338-431a-b8ae-c91cd4a07a14",
   "metadata": {},
   "source": [
    "Performed min-max normalization on all numeric audio features to scale them into a [0, 1] range. \n",
    "This transformation ensures proportional feature contribution by minimizing the influence of high-magnitude variables (like duration_ms)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2de9b3-63ef-4ef2-a9da-739d12fd38f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import scaler to transform numeric data to a range between 0 and 1.\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65074b4-95bc-487b-b973-ab1d6bca5228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only numeric columns\n",
    "df_numeric = df.select_dtypes(include=[np.number])\n",
    "\n",
    "# Normalize using MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df_numeric), columns=df_numeric.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72fbdf4-73fd-471a-a451-ee1ec5012dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec8bf4d-2fe4-410a-8447-581b2bbb1ab5",
   "metadata": {},
   "source": [
    "#### 2.5.2. Count upper and lower bound outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22aa3463-92b0-4f9e-90cd-e9a157605a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_all_outliers(df):\n",
    "    outlier_dict = {}\n",
    "    for col in df.columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        lower_outliers = (df[col] < lower_bound).sum()\n",
    "        upper_outliers = (df[col] > upper_bound).sum()\n",
    "\n",
    "        outlier_dict[col] = {\n",
    "            \"Upper Outliers\": upper_outliers,\n",
    "            \"Lower Outliers\": lower_outliers  \n",
    "        }\n",
    "\n",
    "    outlier_df = pd.DataFrame.from_dict(outlier_dict, orient=\"index\").T\n",
    "    return outlier_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44284177-9007-49ab-be26-2f667870c8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_summary_df = count_all_outliers(df_scaled)\n",
    "outlier_summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b529a19-c945-425e-bd99-403810bb3617",
   "metadata": {},
   "source": [
    "#### 2.5.2. Plot the outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717c6031-7cd8-4572-84b2-c68dde7a048b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the boxplot\n",
    "df_scaled.boxplot(figsize=(10, 6), rot=45)\n",
    "plt.title(\"Boxplot of Normalized Feature Columns\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4e5a0e-6b4a-4387-b5e4-8e4fab3bcbca",
   "metadata": {},
   "source": [
    "#### Insights \n",
    "- **Outlier Presence:** Features like acousticness and speechiness show a high concentration of outliers on the upper end, suggesting some tracks have unusually high values for these characteristics.\n",
    "- Energy, key, valence and tempo appear to be more uniformly distributed, suggesting lower variability and fewer anomalies.\n",
    "- It's also notable that Instrumentalness has a median near zero, indicating that **most tracks are not highly instrumental**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcd75d4-a770-48be-a9c2-530a6536156a",
   "metadata": {},
   "source": [
    "**We'll keep these outliers for this analysis, as top music tracks often have extreme values.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e76ba6-90b2-4b44-9944-8e2dd65b8ff8",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06788358-fd45-4475-9130-20fd6752bda4",
   "metadata": {},
   "source": [
    "### 3.1. Summary of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80ba846-5b2c-4cbd-bef4-1f29deb0664b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_dataframe(df):\n",
    "    \"\"\"\n",
    "    Generate and display a summary of the dataset including\n",
    "    number of observations, number of features, and lists\n",
    "    of categorical and numeric columns.\n",
    "    \"\"\"\n",
    "    categorical = df.select_dtypes(include=\"object\").columns.tolist()\n",
    "    numerical = df.select_dtypes(include=\"number\").columns.tolist()\n",
    "\n",
    "    summary = pd.DataFrame(\n",
    "        {\n",
    "            \"Description\": [\n",
    "                \"Number of observations\",\n",
    "                \"Number of features\",\n",
    "                f\"Categorical features ({len(categorical)})\",\n",
    "                f\"Numeric features ({len(numerical)})\",\n",
    "            ],\n",
    "            \"Value\": [\n",
    "                df.shape[0],\n",
    "                df.shape[1],\n",
    "                \", \".join(categorical),\n",
    "                \", \".join(numerical),\n",
    "            ],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    pd.set_option(\"display.max_colwidth\", None)\n",
    "    display(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca68fac-0558-45c8-9951-c9097f519662",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_dataframe(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c234b163-e164-449c-828d-7ac9375a8510",
   "metadata": {},
   "source": [
    "### 3.2. TOP Artists Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7caea2b9-b654-40ec-9783-01e63d94ec69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many times each artist appears\n",
    "artist_counts = df[\"artist\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82417ab-c06e-4201-8461-8b9abdf0b87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_artists_table(artist_counts, min_tracks=2):\n",
    "    \"\"\"\n",
    "    Return a DataFrame of artists with > 1 tracks.\n",
    "    Adds a 'status' column to indicate top artist(s).\n",
    "    \"\"\"\n",
    "    max_tracks = artist_counts.max()\n",
    "\n",
    "    # Filter artists with ≥ min_tracks\n",
    "    popular_artists = artist_counts[artist_counts >= min_tracks]\n",
    "    df_popular = popular_artists.reset_index()\n",
    "    df_popular.columns = [\"artist\", \"num_top_tracks\"]\n",
    "\n",
    "    # Tag top artist(s)\n",
    "    df_popular[\"status\"] = df_popular[\"num_top_tracks\"].apply(\n",
    "        lambda x: \"Top Artist\" if x == max_tracks else \"Multiple Tracks\"\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"Total Artists: {len(df_popular) + (artist_counts == 1).sum()}\\n\"\n",
    "        f\"Top artist(s) with {max_tracks} track(s): \"\n",
    "        f\"{', '.join(df_popular[df_popular[\"num_top_tracks\"] == max_tracks][\"artist\"])}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Artists with ≥ {min_tracks} top track(s): {len(df_popular)}\\n\"\n",
    "        f\"Artists with 1 top track: {(artist_counts == 1).sum()}\\n\"\n",
    "    )\n",
    "\n",
    "    return df_popular.sort_values(by=\"num_top_tracks\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91bc2c8-b1c3-4375-9ae3-f8baa4c50c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary = summarize_artists_table(artist_counts)\n",
    "display(df_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccf8a11-aeae-4af5-97ce-15599a9cb16f",
   "metadata": {},
   "source": [
    "#### Insights \n",
    "- There are 40 artists in the Top 50 list.\n",
    "- The most popular artists: **Billie Eilish, Dua Lipa, Travis Scott** each having 3 of their tracks in the list.\n",
    "- Justin Bieber, Harry Styles, Lewis Capaldi, Post Malone has 2 of their tracks on the list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ecab12-294b-4b29-b057-993d61eef716",
   "metadata": {},
   "source": [
    "### 3.3. Number of Artists by Track Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543607f5-4ec0-4fc9-aa63-4ba0952d5458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many artists fall into each count bucket\n",
    "artist_freq = artist_counts.value_counts().sort_index()\n",
    "\n",
    "# Create a DataFrame for plotting\n",
    "df_artist_freq = artist_freq.reset_index(name=\"num_artists\")\n",
    "df_artist_freq.columns = [\"track_count\", \"num_artists\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4531f87-81c4-4d46-9add-1ebfc7030c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "plt.figure(figsize=(6, 4))\n",
    "ax = sns.barplot(\n",
    "    x=\"track_count\",\n",
    "    y=\"num_artists\",\n",
    "    data=df_artist_freq,\n",
    "    palette=\"pastel\",\n",
    "    hue=\"track_count\",\n",
    "    legend=False,\n",
    ")\n",
    "\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, fmt=\"%d\", label_type=\"center\", padding=-2)\n",
    "\n",
    "plt.title(\"Number of Artists by Track Count\")\n",
    "plt.xlabel(\"Number of Tracks\")\n",
    "plt.ylabel(\"Number of Artists\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28250d2a-1523-4682-9c69-128b3eba1c46",
   "metadata": {},
   "source": [
    "#### Insights \n",
    "- The vast majority of artists in Top 50 (33 out of 40) have only one track included.\n",
    "- 7 artists have multiple tracks, with 4 artists contributing two tracks and 3 artists contributing three tracks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aefbdf0-023d-49dd-996d-c1bac12530b8",
   "metadata": {},
   "source": [
    "### 3.4. TOP Albums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4344c361-00ed-4cb0-84a5-d3021a741435",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_top_albums(df, min_tracks=2):\n",
    "    \"\"\"\n",
    "    Summarize albums that have > 1 track in top tracks.\n",
    "    Returns a sorted DataFrame with album name, artist, and number of top tracks.\n",
    "    \"\"\"\n",
    "    # Count number of top tracks per album\n",
    "    album_counts = df[\"album\"].value_counts()\n",
    "    multi_track_albums = album_counts[album_counts >= min_tracks].index\n",
    "\n",
    "    # Filter only albums meeting the threshold\n",
    "    df_multi = df[df[\"album\"].isin(multi_track_albums)]\n",
    "\n",
    "    # Group summary by album\n",
    "    df_album_summary = (\n",
    "        df_multi.groupby(\"album\")\n",
    "        .agg(artist=(\"artist\", \"first\"), num_top_tracks=(\"track_name\", \"count\"))\n",
    "        .reset_index()\n",
    "        .sort_values(by=\"num_top_tracks\", ascending=False).reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # Reorder columns\n",
    "    df_album_summary = df_album_summary[[\"album\", \"artist\", \"num_top_tracks\"]]\n",
    "\n",
    "    return df_album_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8c9677-f6b9-4479-9d71-95815b39802c",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(summarize_top_albums(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc835218-e147-496b-bb13-1440fd654aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_albums = df[\"album\"].nunique()\n",
    "print(f\"Total number of unique albums: {unique_albums}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a170b690-63e2-4a0a-b25a-ed7bdb756055",
   "metadata": {},
   "source": [
    "#### Insights \n",
    "- There are 45 albums appearing in the Top 50 list.\n",
    "- 4 Albums appear more than one time\n",
    "- **'Future Nostalgia'** by Dua Lipa is the most popular one, contributing 3 times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5390eeae-bb09-4ee5-8963-ad656569c077",
   "metadata": {},
   "source": [
    "### 3.5. Feature Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd948db-e380-4568-a5b8-fa029599b81a",
   "metadata": {},
   "source": [
    "#### 3.5.1. Danceability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ce3537-d781-4f1b-91b8-079622297434",
   "metadata": {},
   "source": [
    "**High Danceability**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ffb268-6f54-4f3e-ab19-64556a9e2b98",
   "metadata": {},
   "source": [
    "Danceability values **above 0.7** are used as a threshold to define \"high.\" This implies that the track possesses a strong, consistent rhythm, stable tempo, and overall feel that makes it easy to dance to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16c6ede-d594-46a8-83ec-88190534a5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def high_danceability_tracks(df, threshold=0.7):\n",
    "    \"\"\"\n",
    "    Prints and returns tracks with danceability above the given threshold.\n",
    "    \"\"\"\n",
    "    tracks = df[df[\"danceability\"] > threshold].sort_values(\n",
    "        \"danceability\", ascending=False\n",
    "    )\n",
    "    print(\n",
    "        f\"There are {len(tracks)} track(s) that have a danceability score above {threshold}\\n\"\n",
    "    )\n",
    "    return tracks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c686e9c-b7bb-4249-86a5-d71166e736c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_danceability_tracks(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7eb815-0f48-4662-8d41-45daf33cdf84",
   "metadata": {},
   "source": [
    "#### Insights\n",
    "- A significant majority **64%** (32 out of 50) of 2020's top tracks contribute high danceability scores (above 0.7)\n",
    "- The most danceable track: Cardi B's Hip-Hop/Trap hit **'WAP' (Feat. Megan Thee Stallion)**, with score of 0.935"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594097ab-bbbc-423c-8d3d-db9c9ed3e41c",
   "metadata": {},
   "source": [
    "**Low Danceability**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06817570-a819-4e76-b911-81d52efc37c3",
   "metadata": {},
   "source": [
    "Danceability values **below 0.40** indicate that a track has a less prominent beat, an irregular tempo, or a structure that doesn't lend itself easily to dancing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589a3649-7f2e-4af8-859f-03bdbe085670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def low_danceability_tracks(df, threshold=0.4):\n",
    "    \"\"\"\n",
    "    Prints and returns tracks with danceability below the given threshold.\n",
    "    \"\"\"\n",
    "    tracks = df[df[\"danceability\"] < threshold].sort_values(\"danceability\")\n",
    "    print(\n",
    "        f\"There are {len(tracks)} track(s) that have a danceability score below {threshold}\\n\"\n",
    "    )\n",
    "    return tracks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eae7a01-4598-46be-92da-f04d9b1606bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_danceability_tracks(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172194c4-4724-446d-b880-39178e0749c7",
   "metadata": {},
   "source": [
    "#### Insights\n",
    "- Only **2%** (1 out of 50) registered with a low danceability score, indicating its rarity among chart-topping hits.\n",
    "- Lowest Danceability track was Chamber pop hit **'Lovely (With Khalid)'** by Billie Eilish with score of 0.351"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f92bd00-5777-4d15-ab60-22de894dddcf",
   "metadata": {},
   "source": [
    "#### 3.5.2. Loudness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec4e198-3580-4152-9ee0-b72a5a07a039",
   "metadata": {},
   "source": [
    "**High Loudness**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7dd55e-350e-4283-bce7-c789f82e4561",
   "metadata": {},
   "source": [
    "0 dB represents the maximum possible loudness, values approaching it: **-1.0 dB to -5.0 dB** are considered very high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3113c2-e635-49d7-a603-e7163ec7e5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def high_loudness_tracks(df, threshold=-5):\n",
    "    \"\"\"\n",
    "    Prints and returns tracks with loudness above the given threshold.\n",
    "    \"\"\"\n",
    "    tracks = df[df[\"loudness\"] > threshold].sort_values(\"loudness\", ascending=False)\n",
    "    print(\n",
    "        f\"There are {len(tracks)} track(s) that have a loudness score above {threshold}\\n\"\n",
    "    )\n",
    "    return tracks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353c0e8e-bfcd-47bf-9e06-fc5bc02e759b",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_loudness_tracks(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6bb4c4-8f5e-4a57-9e09-0eb808cc6469",
   "metadata": {},
   "source": [
    "#### Insights\n",
    "- Nearly **40%** of the Top 50 tracks (19 songs) register high loudness scores\n",
    "- Pop hit **'Tusa'** by Karol G stands out as the loudest track in the dataset. (-3.280 dB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6888a37c-76dc-4305-ae96-500168d20826",
   "metadata": {},
   "source": [
    "**Low Loudness**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74136bb-7467-4e1a-bf78-22214da39b37",
   "metadata": {},
   "source": [
    "Loudness score is generally considered low when it is: -15.0 dB to -25.0 dB\n",
    "These values indicate a track that is significantly quieter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0600a0c8-2415-4aa7-9f3e-db471f837556",
   "metadata": {},
   "source": [
    "Since there are no values in our dataset in this range, we calculate \"low\" relative to the other tracks in Top 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5459c1ad-8ce8-4268-adb3-dac7026fcecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Quartiles for Loudness ---\")\n",
    "loudness_q1 = df[\"loudness\"].quantile(0.25)\n",
    "loudness_median = df[\"loudness\"].quantile(0.50)\n",
    "loudness_q3 = df[\"loudness\"].quantile(0.75)\n",
    "\n",
    "print(f\"25th Percentile (Q1) Loudness: {loudness_q1:.3f} dB\")\n",
    "print(f\"50th Percentile (Median) Loudness: {loudness_median:.3f} dB\")\n",
    "print(f\"75th Percentile (Q3) Loudness: {loudness_q3:.3f} dB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae499749-c7cc-4bf2-82e8-9ec8166bc29f",
   "metadata": {},
   "source": [
    "- Will use the rounded 25th Percentile of **-8 dB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a287ca6-8715-41c2-a05c-36fe62a78db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def low_loudness_tracks(df, threshold=-8):\n",
    "    \"\"\"\n",
    "    Prints and returns tracks with loudness below the given threshold.\n",
    "    \"\"\"\n",
    "    tracks = df[df[\"loudness\"] < threshold].sort_values(\"loudness\")\n",
    "    print(\n",
    "        f\"There are {len(tracks)} track(s) that have a loudness score below {threshold}\\n\"\n",
    "    )\n",
    "    return tracks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa408b1-ea44-4148-8148-3fa996aaa2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_loudness_tracks(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51982462-0946-4613-a9b1-8bd923106154",
   "metadata": {},
   "source": [
    "#### Insights\n",
    "- Top 50 generally comprises loud tracks\n",
    "- **18%** (9 out of 50) falling into the 'very low' loudness category relative to the rest of our dataset.\n",
    "- The most silent track is the Pop hit **'Everything I Wanted'** by Billie Eilish. Its low loudness score -14.5 dB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c154488e-1dcf-4592-8390-14bddc34cc1d",
   "metadata": {},
   "source": [
    "#### 3.5.3. Length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac64f476-81bc-4e2d-8d9c-a6534662ec72",
   "metadata": {},
   "source": [
    "Calculate the longest and shortest tracks in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d06301d-bc52-478b-bb73-38ccb960a001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_duration(duration_ms):\n",
    "    \"\"\"\n",
    "    Convert duration from milliseconds to mm:ss format.\n",
    "    \"\"\"\n",
    "    seconds = duration_ms / 1000\n",
    "    minutes = int(seconds // 60)\n",
    "    seconds = int(seconds % 60)\n",
    "    return f\"{minutes}:{seconds:02d}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6bf4fe-493e-4432-b863-bc04619fe6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_extreme_duration_tracks(df):\n",
    "    \"\"\"\n",
    "    Returns the longest and shortest tracks in mm:ss format.\n",
    "    \"\"\"\n",
    "    longest = df.loc[df[\"duration_ms\"].idxmax()]\n",
    "    shortest = df.loc[df[\"duration_ms\"].idxmin()]\n",
    "\n",
    "    results = {\n",
    "        \"Type\": [\"Longest\", \"Shortest\"],\n",
    "        \"Track Name\": [longest[\"track_name\"], shortest[\"track_name\"]],\n",
    "        \"Artist\": [longest[\"artist\"], shortest[\"artist\"]],\n",
    "        \"Duration (mm:ss)\": [\n",
    "            format_duration(longest[\"duration_ms\"]),\n",
    "            format_duration(shortest[\"duration_ms\"]),\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada20f37-6473-4d8c-957b-3fc179a1ffad",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_extreme_duration_tracks(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b855341f-34aa-47b5-976a-52edccf7bc80",
   "metadata": {},
   "source": [
    "#### 3.5.4. Genre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082fdc03-abbb-4875-b66f-d4ba5ea8827d",
   "metadata": {},
   "source": [
    "Analyze genre distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bab7a48-37cf-4944-9206-59a1e82deed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_genres(df):\n",
    "    \"\"\"\n",
    "    Analyze genre data to identify:\n",
    "    - The most frequently contributed genre and its track count\n",
    "    - Genres that appear only once, along with their count\n",
    "    - Total number of distinct genres in the dataset\n",
    "    \"\"\"\n",
    "    genre_counts = df[\"genre\"].value_counts()\n",
    "    most_popular_genre = genre_counts.idxmax()\n",
    "    most_popular_count = genre_counts.max()\n",
    "    one_song_genres = genre_counts[genre_counts == 1]\n",
    "    unique_genres = df[\"genre\"].nunique()\n",
    "\n",
    "    print(f\"Most popular genre: '{most_popular_genre}' with {most_popular_count} tracks.\")\n",
    "    print(f\"Genres with only one song ({one_song_genres.count()} total):\\n{one_song_genres}\\n\")\n",
    "    print(f\"Total number of unique genres: {unique_genres}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e83301-db36-4518-95f7-7bddd4d842da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize genre distribution\n",
    "def plot_genre_distribution(df):\n",
    "    genre_counts = df[\"genre\"].value_counts()\n",
    "    genre_counts.plot(kind=\"barh\", figsize=(8, 4), color=\"limegreen\")\n",
    "    plt.title(\"Genre Distribution\")\n",
    "    plt.xlabel(\"Number of Tracks\")\n",
    "    plt.ylabel(\"Genre\")\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f087a54-dd59-4835-8648-f731b986acce",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_genres(df)\n",
    "plot_genre_distribution(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fbe5bd-8b3e-4947-98be-922e36034496",
   "metadata": {},
   "source": [
    "#### Insights\n",
    "- Dominant genres: Pop **28%** (14 tracks) and Hip-Hop/Rap **20%** (10 tracks) together account for nearly half of the most streamed songs.\n",
    "- Dataset includes 16 distinct genres, 10 of which are represented by only one song."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9881fd5-c240-4dae-9a98-053783dc5029",
   "metadata": {},
   "source": [
    "### 3.6. Correlation Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afd211c-402c-4dec-9b48-0fd31fbd53dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_correlations(df, label, lower_bound, upper_bound):\n",
    "    \"\"\"\n",
    "    Extract correlation values between numeric features in a specific range.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame\n",
    "        label: Label for the type of correlation\n",
    "        lower_bound: Lower threshold\n",
    "        upper_bound: Upper threshold\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Filtered correlation matrix\n",
    "    \"\"\"\n",
    "    numeric_df = df.select_dtypes(include=\"number\")\n",
    "    corr_matrix = numeric_df.corr()\n",
    "\n",
    "    # Mask upper triangle to avoid duplicates\n",
    "    mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "    corr_matrix = corr_matrix.mask(mask)\n",
    "\n",
    "    # Filter based on bounds\n",
    "    filtered = corr_matrix[(corr_matrix > lower_bound) & (corr_matrix < upper_bound)]\n",
    "    filtered = filtered.dropna(how=\"all\").dropna(how=\"all\", axis=1)\n",
    "\n",
    "    # Replace NaNs with dash for display\n",
    "    filtered = filtered.fillna(\"-\")\n",
    "    \n",
    "    print(f\"{label} features (correlation between {lower_bound} and {upper_bound}):\") \n",
    "\n",
    "\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590c2f0f-018e-40c6-9a93-ef8b0d6ad1ce",
   "metadata": {},
   "source": [
    "#### 3.6.1. Strongly Positive Corellation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c837e1-55a2-4764-96cb-f0b197854b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_correlations(df, \"Strongly positive\", 0.7, 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a93697d-d81a-4443-8377-7e9b9c67e569",
   "metadata": {},
   "source": [
    "#### 3.6.2. Strongly Negative Corellation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb36c4b0-ae0f-4b4e-a94b-abdeb923ea17",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_correlations(df, \"Strongly negative\", -1.0, -0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a2eb07-1684-4896-b468-0c17953245a1",
   "metadata": {},
   "source": [
    "#### 3.6.3. Weak to no correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1372523d-c346-4833-82a6-ca0132270c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_correlations(df, \"Weak to no correlation\", -0.1, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36598824-dd28-4b5b-bb31-c838e281baab",
   "metadata": {},
   "source": [
    "#### Insights\n",
    "- **Energy ↔ Loudness:** With a correlation of 0.79, these two are closely linked—meaning louder tracks tend to be more energetic.\n",
    "- **Energy ↔ Acousticness:** Correlation of -0.68 suggests that more acoustic tracks tend to be less energetic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a431e559-8e0c-4fa2-911a-f0b7061a8d9d",
   "metadata": {},
   "source": [
    "## 4. Statistical Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877b242a-e4bd-4925-846a-64e9c11e3508",
   "metadata": {},
   "source": [
    "This section examines the feature **(danceability, loudness, acousticness)** scores across top 4 music genres by:\n",
    "- Comparing their mean feature values\n",
    "- Visualizing score distributions\n",
    "- Conducting pairwise t-tests to assess whether observed differences are statistically significant\n",
    "\n",
    "The goal is to determine if these features varies meaningfully between: Pop, Hip-Hop/Rap, Dance/Electronic, and Alternative/Indie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c877587d-2021-4fbd-b6d5-76ba9679d1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define genre selection\n",
    "selected_genres = [\"Pop\", \"Hip-Hop/Rap\", \"Dance/Electronic\", \"Alternative/Indie\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b1ef0a-9fd8-4955-afcd-f591ef0a729b",
   "metadata": {},
   "source": [
    "### 4.1. Danceability between genres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf601b7e-ca05-475f-9a17-6e1232bc5345",
   "metadata": {},
   "source": [
    "#### 4.1.1 Danceability Means Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc0067e-7471-4165-a3bd-2b6ac7763ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average danceability scores for selected genres\n",
    "genre_danceability = (\n",
    "    df.groupby(\"genre\")[\"danceability\"]\n",
    "    .mean()\n",
    "    .loc[selected_genres]\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "print(\"Danceability scores comparison between selected genres:\")\n",
    "display(genre_danceability.to_frame())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfafebb2-008a-4f6e-ad58-a1b653e1efc8",
   "metadata": {},
   "source": [
    "#### 4.1.2. Danceability Score Distributio Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c22cdd-352e-4311-a05a-f0de94f521a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Violin plot of danceability distributions by genre\n",
    "filtered_df = df[df[\"genre\"].isin(selected_genres)]\n",
    "genre_medians = filtered_df.groupby(\"genre\")[\"danceability\"].median()\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.violinplot(data=filtered_df, x=\"genre\", y=\"danceability\", inner=\"box\")\n",
    "\n",
    "# Annotate medians\n",
    "for i, genre in enumerate(selected_genres):\n",
    "    median = genre_medians[genre]\n",
    "    plt.text(i, median + 0.1, f\"Median: {median:.2f}\", ha=\"center\", color=\"red\")\n",
    "\n",
    "# Plot\n",
    "plt.title(\"Danceability Score Distribution by Genre\", fontsize=14)\n",
    "plt.ylabel(\"Danceability\")\n",
    "plt.xlabel(\"Genre\")\n",
    "plt.xticks(rotation=15)\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc71d5d4-8925-4e80-91fa-560c389a4193",
   "metadata": {},
   "source": [
    "####  Insights\n",
    "- Dance/Electronic leads with the highest median danceability at 0.79\n",
    "- Dance/Electronic and Hip-Hop/Rap genres are less spread, meaning their tracks consistently aim for higher danceability.\n",
    "- Alternative/Indie and Pop have wider distributions, displaying more variation across tracks — from danceable hits to mellow ballads."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875e2ab9-8c85-4167-8b61-583d2b7218b1",
   "metadata": {},
   "source": [
    "#### 4.1.3. Danceability T-Test Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ec1859-b667-424a-bf79-253b30a0262c",
   "metadata": {},
   "source": [
    "General Hypotheses for Danceability Comparison Between Two Genres:\n",
    "\n",
    "- Null Hypothesis (H₀): There is no difference in the mean danceability between the selected genre pairs.\n",
    "- Alternative Hypothesis (H₁): There is a difference in the mean danceability between the two genres.\n",
    "\n",
    "This is a two-tailed test, evaluating whether one genre tends to be more or less danceable than the other on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29399b0-f7d8-40b5-888c-fc5f46f914de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairwise T-tests for danceability between genres\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, genre_a in enumerate(selected_genres):\n",
    "    for genre_b in selected_genres[i + 1:]:\n",
    "        group_a = df[df[\"genre\"] == genre_a][\"danceability\"]\n",
    "        group_b = df[df[\"genre\"] == genre_b][\"danceability\"]\n",
    "        \n",
    "        t_stat, p_value = ttest_ind(group_a, group_b, equal_var=False, nan_policy=\"omit\")\n",
    "        \n",
    "        results.append({\n",
    "            \"Genre A\": genre_a,\n",
    "            \"Genre B\": genre_b,\n",
    "            \"T-Statistic\": round(t_stat, 3),\n",
    "            \"P-Value\": round(p_value, 4),\n",
    "            \"Significant\": \"Yes\" if p_value < 0.05 else \"No\"\n",
    "        })\n",
    "\n",
    "ttest_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"Danceability Genre Pairwise T-Test Results:\")\n",
    "display(ttest_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1977201-b401-4076-8924-22aedad4938e",
   "metadata": {},
   "source": [
    "#### Results:\n",
    "\n",
    "Pop vs. Hip-Hop/Rap shows a statistically significant difference in danceability\n",
    "- P-value: 0.0284 < 0.05 → We reject the null hypothesis\n",
    "- **Hip-Hop/Rap is considered more danceable than Pop**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5909b09f-cf07-4d43-b91d-6ed15ff63860",
   "metadata": {},
   "source": [
    "#### 4.1.4. Effect Size (Cohen’s d) for Two Independent Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae406821-a8a5-49dd-8883-a1e2e4280abd",
   "metadata": {},
   "source": [
    "We calculate effect size, which tells us how big/meaningful the difference is between these groups, beyond statistical significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1321b413-0ec8-4f72-aaf1-5aa7be0923bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cohens_d(group1, group2):\n",
    "    \"\"\"Compute Cohen's d for two independent samples.\"\"\"\n",
    "    mean_diff = np.mean(group1) - np.mean(group2)\n",
    "    pooled_std = np.sqrt(\n",
    "        ((np.std(group1, ddof=1) ** 2) + (np.std(group2, ddof=1) ** 2)) / 2\n",
    "    )\n",
    "    return round(mean_diff / pooled_std, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69c585b-b05b-47eb-8f3b-ec2ed2486c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret_effect_size(d):\n",
    "    abs_d = abs(d)\n",
    "    if abs_d < 0.2:\n",
    "        return \"Negligible\"\n",
    "    elif abs_d < 0.5:\n",
    "        return \"Small\"\n",
    "    elif abs_d < 0.8:\n",
    "        return \"Medium\"\n",
    "    else:\n",
    "        return \"Large\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07d2d35-26b8-4170-95b7-a91b2039ec64",
   "metadata": {},
   "outputs": [],
   "source": [
    "effect_sizes = []\n",
    "\n",
    "for i, genre_a in enumerate(selected_genres):\n",
    "    for genre_b in selected_genres[i + 1:]:\n",
    "        group_a = df[df[\"genre\"] == genre_a][\"danceability\"].dropna()\n",
    "        group_b = df[df[\"genre\"] == genre_b][\"danceability\"].dropna()\n",
    "        \n",
    "        d = cohens_d(group_a, group_b)\n",
    "        interpretation = interpret_effect_size(d)\n",
    "\n",
    "        effect_sizes.append({\n",
    "            \"Genre A\": genre_a,\n",
    "            \"Genre B\": genre_b,\n",
    "            \"Cohen's d\": d,\n",
    "            \"Interpretation\": interpretation\n",
    "\n",
    "        })\n",
    "\n",
    "effect_sizes_danceability_df = pd.DataFrame(effect_sizes)\n",
    "display(effect_sizes_danceability_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862497c7-e68b-4371-9b35-7721690daee6",
   "metadata": {},
   "source": [
    "A large effect size supports the conclusion that Hip-Hop/Rap is notably more danceable than Pop.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15416fd2-2a12-4891-b890-6fb9662dab36",
   "metadata": {},
   "source": [
    "### 4.2. Loudness between genres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d18a015-77f8-42df-937b-9afa6c1d7175",
   "metadata": {},
   "source": [
    "#### 4.2.1. Loudness Means Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9f2027-4bb9-482c-94b2-e943b6ba954f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average loudness scores for selected genres\n",
    "genre_loudness = (\n",
    "    df.groupby(\"genre\")[\"loudness\"]\n",
    "    .mean()\n",
    "    .loc[selected_genres]\n",
    "    .sort_values()\n",
    ")\n",
    "\n",
    "print(\"Loudness scores comparison between selected genres:\")\n",
    "display(genre_loudness.to_frame())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782b60bf-1668-4f3b-8a09-4b0fd7d4568a",
   "metadata": {},
   "source": [
    "#### 4.2.2. Loudnes Score Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88f9c43-bc69-4905-bcff-77d1cbed3d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Violin plot of loudness distributions by genre\n",
    "filtered_df = df[df[\"genre\"].isin(selected_genres)]\n",
    "genre_medians = filtered_df.groupby(\"genre\")[\"loudness\"].median()\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.violinplot(data=filtered_df, x=\"genre\", y=\"loudness\", inner=\"box\")\n",
    "\n",
    "# Annotate medians\n",
    "for i, genre in enumerate(selected_genres):\n",
    "    median = genre_medians[genre]\n",
    "    plt.text(i, median + 0.1, f\"Median: {median:.2f}\", ha=\"center\", color=\"red\")\n",
    "\n",
    "# Plot\n",
    "plt.title(\"Loudness Score Distribution by Genre\", fontsize=14)\n",
    "plt.ylabel(\"Loudness\")\n",
    "plt.xlabel(\"Genre\")\n",
    "plt.xticks(rotation=15)\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04de85bc-cb1e-48ca-9d11-58fd8c15f9b2",
   "metadata": {},
   "source": [
    "####  Insights\n",
    "- Pop is the loudest genre overall by its median loudness of –5.27 dB\n",
    "- Alternative/Indie presents a moderately dispersed distribution, generally lower loudness levels.\n",
    "- Hip-Hop/Rap demonstrates the broadest loudness range.\n",
    "- Dance/Electronic and Pop genres exhibit relatively tight loudness distributions, indicating consistency in audio across their respective tracks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f696d45-71b5-4c3a-90b7-876d164b228c",
   "metadata": {},
   "source": [
    "#### 4.2.3. Loudness T-Test Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8bad26-66ce-4955-864d-0100aa6c802c",
   "metadata": {},
   "source": [
    "General Hypotheses for Loudness Comparison Between Two Genres:\n",
    "\n",
    "- Null Hypothesis (H₀): There is no difference in the mean loudness between selected genre pairs.\n",
    "- Alternative Hypothesis (H₁): There is a difference in the mean loudness between the two genres.\n",
    "\n",
    "This is a two-tailed test, testing whether one genre is either louder or softer on average than the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b190edb-3bae-4e96-98eb-468c53654adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairwise T-tests for loudness between genres\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, genre_a in enumerate(selected_genres):\n",
    "    for genre_b in selected_genres[i + 1:]:\n",
    "        group_a = df[df[\"genre\"] == genre_a][\"loudness\"]\n",
    "        group_b = df[df[\"genre\"] == genre_b][\"loudness\"]\n",
    "        \n",
    "        t_stat, p_value = ttest_ind(group_a, group_b, equal_var=False, nan_policy=\"omit\")\n",
    "        \n",
    "        results.append({\n",
    "            \"Genre A\": genre_a,\n",
    "            \"Genre B\": genre_b,\n",
    "            \"T-Statistic\": round(t_stat, 3),\n",
    "            \"P-Value\": round(p_value, 4),\n",
    "            \"Significant\": \"Yes\" if p_value < 0.05 else \"No\",\n",
    "            \"Louder Genre\": genre_a if group_a.mean() > group_b.mean() else genre_b\n",
    "\n",
    "\n",
    "        })\n",
    "\n",
    "ttest_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"Loudness Genre Pairwise T-Test Results:\")\n",
    "display(ttest_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac3e3f0-dde1-44f0-afab-6706be6d9a70",
   "metadata": {},
   "source": [
    "#### Insights\n",
    "\n",
    "Hip-Hop/Rap vs. Alternative/Indie shows a statistically significant difference in loudness\n",
    "\n",
    "- P-value: 0.0389 < 0.05 → We reject the null hypothesis\n",
    "- **Alternative/Indie is louder than Hip-Hop/Rap**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33acc387-420d-483e-a0f7-f0100e363052",
   "metadata": {},
   "source": [
    "#### 4.3.4. Effect Size (Cohen’s d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4e336c-e6b3-46c7-a7a1-e6bc7201dbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "effect_sizes = []\n",
    "\n",
    "for i, genre_a in enumerate(selected_genres):\n",
    "    for genre_b in selected_genres[i + 1:]:\n",
    "        group_a = df[df[\"genre\"] == genre_a][\"loudness\"].dropna()\n",
    "        group_b = df[df[\"genre\"] == genre_b][\"loudness\"].dropna()\n",
    "        \n",
    "        d = cohens_d(group_a, group_b)\n",
    "        interpretation = interpret_effect_size(d)\n",
    "\n",
    "        effect_sizes.append({\n",
    "            \"Genre A\": genre_a,\n",
    "            \"Genre B\": genre_b,\n",
    "            \"Cohen's d\": d,\n",
    "            \"Interpretation\": interpretation\n",
    "\n",
    "        })\n",
    "\n",
    "effect_sizes_loudness_df = pd.DataFrame(effect_sizes)\n",
    "display(effect_sizes_loudness_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84cedf0-5626-47a8-8cb1-b3bf453b1398",
   "metadata": {},
   "source": [
    "A large effect size supports the conclusion that Alternative/Indie is louder than Hip-Hop/Rap.\n",
    "\n",
    "**Note: Observed a Large difference between Hip-Hop/Rap and Dance/Electronic**\n",
    "\n",
    "- A large Cohen's d (–0.930) tells us that the difference in loudness is quite substantial.  \n",
    "\n",
    "- But T-test p-value (even lowered to 0.01) was not significant, which means:  \n",
    "\n",
    "    - The difference might be practically meaningful (big gap in values) but there's still too much uncertainty to confidently say it's real with this test.\n",
    "\n",
    "\n",
    "**Consider:** increasing the sample size—more tracks could reduce noise and help reach significance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38effeb2-265e-4458-add8-6a67c2b3667a",
   "metadata": {},
   "source": [
    "### 4.3 Acousticness between genres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22577328-3774-4b12-867c-d2ee75f4a4be",
   "metadata": {},
   "source": [
    "#### 4.3.1. Acousticness Means Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf95cf7-3903-43c8-9bee-50e615f05eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average acousticness scores for selected genres\n",
    "genre_acousticness = (\n",
    "    df.groupby(\"genre\")[\"acousticness\"]\n",
    "    .mean()\n",
    "    .loc[selected_genres]\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "print(\"Acousticness scores comparison between selected genres:\")\n",
    "display(genre_acousticness.to_frame())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc128d45-4ebd-4f9d-ba92-02d07f0afb3c",
   "metadata": {},
   "source": [
    "#### 4.3.2. Acousticness Score Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692819f5-f1ce-47d2-b246-1a8d9c9d6895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Violin plot of acousticness distributions by genre\n",
    "filtered_df = df[df[\"genre\"].isin(selected_genres)]\n",
    "genre_medians = filtered_df.groupby(\"genre\")[\"acousticness\"].median()\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.violinplot(data=filtered_df, x=\"genre\", y=\"acousticness\", inner=\"box\")\n",
    "\n",
    "# Annotate medians\n",
    "for i, genre in enumerate(selected_genres):\n",
    "    median = genre_medians[genre]\n",
    "    plt.text(i, median + 0.1, f\"Median: {median:.2f}\", ha=\"center\", color=\"red\")\n",
    "\n",
    "# Plot\n",
    "plt.title(\"Acousticness Score Distribution by Genre\", fontsize=14)\n",
    "plt.ylabel(\"Acousticness\")\n",
    "plt.xlabel(\"Genre\")\n",
    "plt.xticks(rotation=15)\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41a450b-efeb-4f95-8056-51f2f8bb66fc",
   "metadata": {},
   "source": [
    "#### Insights\n",
    "- Pop exhibits the highest median acousticness (0.65)\n",
    "- Pop and Alternative/Indie show bigger variability in acousticness.\n",
    "- Dance/Electronic has the tightest distribution, reinforcing its low acousticness across tracks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a698029-cfeb-498d-bbe0-dbb5add405e7",
   "metadata": {},
   "source": [
    "#### 4.3.3. Acousticness T-Test Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5788a2eb-dd61-4f05-93a2-afc0ff93be6f",
   "metadata": {},
   "source": [
    "General Hypotheses for Acousticness Comparison Between Two Genres:\n",
    "\n",
    "- Null Hypothesis (H₀): There is no difference in the mean acousticness between selected genre pairs.\n",
    "- Alternative Hypothesis (H₁): There is a difference in the mean acousticness between the two genres.\n",
    "\n",
    "This is a two-tailed test, testing whether one genre is either more or less acoustic on average than the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f701a36-e8db-45e8-ba73-98cba7aa7538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairwise T-tests for acousticness between genres\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, genre_a in enumerate(selected_genres):\n",
    "    for genre_b in selected_genres[i + 1:]:\n",
    "        group_a = df[df[\"genre\"] == genre_a][\"acousticness\"]\n",
    "        group_b = df[df[\"genre\"] == genre_b][\"acousticness\"]\n",
    "        \n",
    "        t_stat, p_value = ttest_ind(group_a, group_b, equal_var=False, nan_policy=\"omit\")\n",
    "        \n",
    "        results.append({\n",
    "            \"Genre A\": genre_a,\n",
    "            \"Genre B\": genre_b,\n",
    "            \"T-Statistic\": round(t_stat, 3),\n",
    "            \"P-Value\": round(p_value, 4),\n",
    "            \"Significant\": \"Yes\" if p_value < 0.05 else \"No\"\n",
    "        })\n",
    "\n",
    "ttest_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"Acousticness Genre Pairwise T-Test Results:\")\n",
    "display(ttest_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dd64ae-3cb2-4625-a23f-b8d36fc21010",
   "metadata": {},
   "source": [
    "There are three pairs that show a statistically significant difference in acousticness.\n",
    "\n",
    "- **Alternative/Indie is more acoustic than Dance/Electronic and Hip-Hop/Rap**\n",
    "- **Pop is more acoustic than Dance/Electronic**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb07715-3eae-47d7-bce6-102f03441167",
   "metadata": {},
   "source": [
    "#### 4.3.4. Effect Size (Cohen’s d) for Two Independent Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914b3d8a-7bee-4b56-9b80-91156b36c57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "effect_sizes = []\n",
    "\n",
    "for i, genre_a in enumerate(selected_genres):\n",
    "    for genre_b in selected_genres[i + 1:]:\n",
    "        group_a = df[df[\"genre\"] == genre_a][\"acousticness\"].dropna()\n",
    "        group_b = df[df[\"genre\"] == genre_b][\"acousticness\"].dropna()\n",
    "        \n",
    "        d = cohens_d(group_a, group_b)\n",
    "        interpretation = interpret_effect_size(d)\n",
    "\n",
    "        effect_sizes.append({\n",
    "            \"Genre A\": genre_a,\n",
    "            \"Genre B\": genre_b,\n",
    "            \"Cohen's d\": d,\n",
    "            \"Interpretation\": interpretation\n",
    "\n",
    "        })\n",
    "\n",
    "effect_sizes_df = pd.DataFrame(effect_sizes)\n",
    "display(effect_sizes_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bc9905-dab1-41f7-9b36-d1b3370a3b57",
   "metadata": {},
   "source": [
    "#### Overall Insights:\n",
    "- It is confirmed that **Alternative/Indie** is more acoustic than Dance/Electronic and Hip-Hop/Rap\n",
    "- Also, Pop is more acoustic than Dance/Electronic\n",
    "- The **strongest contrast** is between **Alternative/Indie** and **Dance/Electronic**.\n",
    "\n",
    "Note: Observed a Large difference between Pop and Alternative/Indie, but there is uncertainty to confidently say it's real difference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae897d0-7a5b-4a65-ab22-d89210dbacea",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis Highlights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2220489c-83f9-49cc-b002-8fa10af38961",
   "metadata": {},
   "source": [
    "- **Top Artists:** Billie Eilish, Dua Lipa, and Travis Scott are the most featured artists, each with three songs in the top 50. \n",
    "- **Top Album:** Dua Lipa's album, \"Future Nostalgia,\" is the most prominent album with three tracks.\n",
    "- **Genre Dominance:** Pop and Hip-Hop/Rap are the most dominant genres, making up nearly half of the top tracks.\n",
    "- The dataset contains 16 unique genres, with 10 of them appearing only once."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1312c617-2624-43ca-a06b-10f77fa50193",
   "metadata": {},
   "source": [
    "Key Audio Features:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c2feba-2e09-432b-9fe4-b0da52118909",
   "metadata": {},
   "source": [
    "- Danceability: **A majority of the top tracks (64%) are highly danceable.** Hip-Hop/Rap tracks are significantly more danceable than Pop tracks.\n",
    "- Loudness: Top tracks are generally loud. Alternative/Indie tracks are, on average, louder than Hip-Hop/Rap tracks.\n",
    "- Acousticness: **Alternative/Indie tracks have the highest acousticness**, while Dance/Electronic tracks have the lowest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c960a77-6aed-4c9b-8ddc-3660e33d8382",
   "metadata": {},
   "source": [
    "Feature Correlations:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6a7cfe-29bf-41fb-be4c-4ae45806bb44",
   "metadata": {},
   "source": [
    "- There is a strong positive correlation between a track's energy and its loudness.\n",
    "- There is a strong negative correlation between energy and acousticness, meaning more acoustic songs tend to be less energetic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc49851-27b7-495b-9b7c-cf9bb8ec8c45",
   "metadata": {},
   "source": [
    "The song lengths in the top 50 vary, with:\n",
    "- Longest: \"Sicko Mode\" by Travis Scott (5:12)\n",
    "- Shortest: \"Mood\" by 24kGoldn (2:20)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d21642a-0c81-4b5e-893a-d379114466d9",
   "metadata": {},
   "source": [
    "### Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d8b31f-03e9-4fd7-89ed-d7a36cf94ccd",
   "metadata": {},
   "source": [
    "For Marketing & Promotional Strategies:\n",
    "\n",
    "- **Leverage Top Performers:** Feature the top artists (Billie Eilish, Dua Lipa, Travis Scott) and the top album (\"Future Nostalgia\") in marketing campaigns to capitalize on their popularity.\n",
    "- **Create Themed Campaigns:** Develop marketing initiatives based on audio features like \"high-danceability\" playlists or \"high-energy\" workout mixes to target specific listener preferences.\n",
    "- **Target Genre-Specific Audiences:** Use the genre insights to tailor marketing efforts. For example, promote high-danceability Hip-Hop/Rap tracks to audiences interested in dance and parties."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422205a6-9665-4bf9-b5ab-3d837e0b08f6",
   "metadata": {},
   "source": [
    "For Data Analysis & Future Research:\n",
    "\n",
    "- **Explore Sub-Genres:** Investigate the dominant \"Pop\" category further to identify which sub-genres are most successful.\n",
    "- **Analyze Audio Feature Drivers:** Conduct a deeper analysis to understand the specific musical elements (like BPM, rhythm, and instrumentation) that contribute to high or low scores in danceability and acousticness.\n",
    "- **Expand the Dataset:** To validate these trends, analyze a larger and more diverse dataset of popular music from different years or regions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
